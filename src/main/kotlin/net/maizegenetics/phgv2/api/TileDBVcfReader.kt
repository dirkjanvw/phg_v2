package net.maizegenetics.phgv2.api

import io.tiledb.java.api.*
import io.tiledb.java.api.Array
import io.tiledb.libvcfnative.VCFReader
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.charset.Charset
import java.util.*

/**
 * Gets data from a TileDB-VCF database. The constructor requires a uri (path) for the database and
 * a list of samples to be returned. If the sample list is empty or null (the default),
 * then all samples in the database will be returned. The positions to be returned can be specified using
 * the [ranges] method. If the ranges to be returned is not set then all positions in the database will be returned.
 *
 * The method [data] returns a list of [SampleData] for the specified samples and positions.
 * Each SampleData contains a variant for a single sample. The SampleData list returned is not sorted.
 *
 * In addition, there are methods for getting the list of all sample names in the database, [sampleNames],
 * and getting the vcf header, as a String, for a sample name [headerForSample].
 *
 * The class has dependencies on repo/tiledb-java-0.19.6-SNAPSHOT.jar and repo/tiledb-vcf-java-0.25.2.jar.
 * Those were created by running gradlew shadowjar on the TileDB-Java repository and the TileDB-VCF/apis/java
 * repository and contain platform specific libraries generated by the build.
 * They were built on Ubuntu 20.04 and will probably run on other Linux versions, but that has not been tested.
 */
class TileDBVcfReader(val uri: String, samples: List<String>? = null) {

    private val dbReader: VCFReader
    private val missingInt = -1

    /**
     * A position range (contig, start, and end) and genotype. Genotype is the allele/haplotype id, not the integer GT code.
     * Genotype and AD are lists to accommodate different ploidy levels.
     */
    data class SampleData(val sampleName: String, val contig: String, val startPos: Int, val endPos: Int, val genotype: List<String>, val AD: List<Int>? = null, val DP: Int? = null)

    init {
        dbReader = if (samples == null) VCFReader(uri, null, Optional.empty(), Optional.empty())
        else {
            VCFReader(uri, samples.toTypedArray(), Optional.empty(), Optional.empty())
        }
    }

    /**
     * Sets range to be returned by the call to the tiledb database.
     * Takes a list of ranges as input. Each range is a string that is "contig:start-end" or "contig"
     */
    fun ranges(range: List<String>): TileDBVcfReader {
        val rangeString = range.map { it.toString() }.toTypedArray()
        dbReader.setRanges(rangeString)
        return this
    }

    fun sampleNames(): List<String> {
        //buffer size
        //buffer size should be adequate as the query is called iteratively until all sample names have been read
        val bufferSize = 10000

        // Open array and read samples
        val tiledbUri = "${uri}/metadata/vcf_headers"
        val context = Context()
        val array = Array(context, tiledbUri, QueryType.TILEDB_READ)
        val query = Query(array, QueryType.TILEDB_READ)

        // alloc buffers
        query.setDataBuffer("sample", NativeArray(context, bufferSize, Datatype.TILEDB_STRING_ASCII))
        query.setOffsetsBuffer("sample", NativeArray(context, bufferSize, Datatype.TILEDB_UINT64))

        val samples = ArrayList<String>()

        // submit query
        do {
            query.submit()
            val data = query.getBuffer("sample") as ByteArray
            val offsets = query.getOffsetsBuffer("sample")

            for (ndx in 0 ..< offsets.size - 1) {
                samples.add(data.sliceArray(offsets[ndx].toInt()..<offsets[ndx+1].toInt()).toString(Charset.forName("US-ASCII")))
            }
            samples.add(data.sliceArray(offsets.last().toInt()..< data.size).toString(Charset.forName("US-ASCII")))

        } while (query.queryStatus === QueryStatus.TILEDB_INCOMPLETE) // run until query complete

        context.close()
        array.close()
        query.close()

        return samples
    }

    fun headerForSample(sampleName: String): String {
        // open array
        val tiledbUri = "${uri}/metadata/vcf_headers"
        val context = Context()
        val array = Array(context, tiledbUri, QueryType.TILEDB_READ)

        // slice on a specific sample
        val subArray = SubArray(context, array)
        subArray.addRangeVar(0, sampleName, sampleName)
        val query = Query(array, QueryType.TILEDB_READ)
        query.setSubarray(subArray)

        // alloc buffers
        var bufferSize = 1000000
        query.setDataBuffer("header", NativeArray(context, bufferSize, Datatype.TILEDB_STRING_ASCII))
        query.setOffsetsBuffer("header", NativeArray(context, 1024, Datatype.TILEDB_UINT64))
        var data: ByteArray

        // submit query
        do {
            query.submit()
            data = query.getBuffer("header") as ByteArray
            if (data.isEmpty() && query.queryStatus === QueryStatus.TILEDB_INCOMPLETE) {
                // if buffer size is small increase the size by a factor of 2
                bufferSize *= 2
                query.setDataBuffer("header", NativeArray(context, bufferSize, Datatype.TILEDB_CHAR))
                query.setOffsetsBuffer("header", NativeArray(context, 1024, Datatype.TILEDB_UINT64))
            }
        } while (query.queryStatus === QueryStatus.TILEDB_INCOMPLETE) // run until query complete
        context.close()
        array.close()
        query.close()

        return data.toString(Charset.forName("US-ASCII"))
    }

    fun data(): List<SampleData> {
        val capacity = 1024
        val attributeNames = arrayOf(
            "sample_name",
            "contig",
            "pos_start",
            "pos_end",
            "alleles",
            "fmt_GT",
            "fmt_AD",
            "fmt_DP"
        )

        //delete any attributes not in this tiledb
        val attributeInfo = dbReader.attributes
        val filteredAttributeNames = attributeNames.filter { attributeInfo.keys.contains(it) }
        val hasAD = filteredAttributeNames.contains("fmt_AD")
        val hasDP = filteredAttributeNames.contains("fmt_DP")

        //set buffers
        //buffers for all candidate attributes that are in the database
        for (attribute in filteredAttributeNames) dbReader.setBuffer(attribute,
            ByteBuffer.allocateDirect(capacity).order(ByteOrder.nativeOrder()))

        //needed for variable length attributes
        attributeNames.filter { attributeInfo[it]?.isVarLen ?: false }.forEach {
            dbReader.setBufferOffsets(it, ByteBuffer.allocateDirect(capacity).order(ByteOrder.nativeOrder()))
        }

        //needed for nullable attributes
        attributeNames.filter { attributeInfo[it]?.isNullable ?: false }.forEach {
            dbReader.setBufferValidityBitmap(it, ByteBuffer.allocateDirect(capacity).order(ByteOrder.nativeOrder()))
        }

        //needed for list attributes
        attributeNames.filter { attributeInfo[it]?.isList ?: false }.forEach {
            dbReader.setBufferListOffsets(it, ByteBuffer.allocateDirect(capacity).order(ByteOrder.nativeOrder()))
        }

        //process data
        val sampleNames = mutableListOf<String>()
        val contigs = mutableListOf<String>()
        val startPositions = mutableListOf<Int>()
        val endPositions = mutableListOf<Int>()
        val genotypes = mutableListOf<List<String>>()
        val ADs = mutableListOf<List<Int>>()
        val DPs = mutableListOf<Int>()

        while (!dbReader.status.equals(VCFReader.Status.COMPLETED)) {
            dbReader.submit()
            val numberOfRecords = dbReader.numRecords.toInt()

            //get sample names
            decodeVarlenChar(
                dbReader.getBuffer("sample_name"),
                dbReader.getOffsets("sample_name"),
                numberOfRecords,
                sampleNames
            )

            //get contig (contig, varlen, CHAR)
            decodeVarlenChar(
                dbReader.getBuffer("contig"),
                dbReader.getOffsets("contig"),
                numberOfRecords,
                contigs
            )

            //get startPos (pos_start, INT32)
            decodeInt(
                dbReader.getBuffer("pos_start"),
                numberOfRecords,
                startPositions
            )

            //get endPos (pos_end, INT32)
            decodeInt(
                dbReader.getBuffer("pos_end"),
                numberOfRecords,
                endPositions
            )

            //get genotype (alleles, varlen list of CHAR; fmt_GT, varlen, nullable, INT32)
            //get alleles and fmt_GT, then derive genotypes
            val gtList = mutableListOf<List<Int>>()
            val alleles = mutableListOf<List<String>>()

            decodeVarlenNullableInt(dbReader.getBuffer("fmt_GT"),
                dbReader.getOffsets("fmt_GT"),
                BitSet.valueOf(dbReader.getBitMap("fmt_GT")),
                numberOfRecords,
                gtList
            )

            decodeVarlenListChar(dbReader.getBuffer("alleles"),
                dbReader.getOffsets("alleles"),
                dbReader.getListOffsets("alleles"),
                numberOfRecords,
                alleles
            )

            for (ndx in 0 until numberOfRecords) {
                val currAlleles = alleles[ndx]
                val geno = gtList[ndx].map { if( it < 0) "." else currAlleles[it] }
                genotypes.add(geno)
            }

            //get AD (fmt_AD, varlen, nullable, INT32)
            if (hasAD) {
                decodeVarlenNullableInt(dbReader.getBuffer("fmt_AD"),
                    dbReader.getOffsets("fmt_AD"),
                    BitSet.valueOf(dbReader.getBitMap("fmt_AD")),
                    numberOfRecords, ADs
                )
            }

            //get DP (fmt_DP, nullable, INT32)
            if (hasDP) {
                decodeNullableInt(dbReader.getBuffer("fmt_DP"),
                    BitSet.valueOf(dbReader.getBitMap("fmt_DP")),
                    numberOfRecords,
                    DPs
                )
            }

        }

        //convert values to a list of sample data
        return sampleNames.indices.map { SampleData(sampleNames[it], contigs[it],
            startPositions[it], endPositions[it], genotypes[it],
            if (hasAD) ADs[it] else null, if (hasDP) DPs[it] else null) }

    }

    private fun decodeVarlenChar(dataBuffer: ByteBuffer,
                         offsetBuffer: ByteBuffer,
                         numberOfRecords: Int,
                         outputList: MutableList<String>)  {
        val offsets = IntArray(numberOfRecords + 1)
        offsetBuffer.asIntBuffer().get(offsets)
        for (ndx in 0..<numberOfRecords) {
            val sizeOfName = offsets[ndx + 1] - offsets[ndx]
            val nameByteArray = ByteArray(sizeOfName)
            dataBuffer.get(nameByteArray)
            outputList.add(nameByteArray.decodeToString())
        }
    }

    private fun decodeInt(dataBuffer: ByteBuffer,
                  numberOfRecords: Int,
                  outputList: MutableList<Int>) {
        val data = IntArray(numberOfRecords)
        dataBuffer.asIntBuffer().get(data)
        outputList.addAll(data.toList())
    }

    private fun decodeVarlenListChar(dataBuffer: ByteBuffer,
                             offsetBuffer: ByteBuffer,
                             listOffsetBuffer: ByteBuffer,
                             numberOfRecords: Int,
                             outputList: MutableList<List<String>>) {
        val nameList = mutableListOf<String>()
        decodeVarlenChar(dataBuffer, offsetBuffer, numberOfRecords, nameList)
        val listOffsets = IntArray(numberOfRecords + 1)
        listOffsetBuffer.asIntBuffer().get(listOffsets)
        val numberOfValues = listOffsets[numberOfRecords]
        decodeVarlenChar(dataBuffer, offsetBuffer, numberOfValues, nameList)
        for (ndx in 0 until numberOfRecords) {
            outputList.add(nameList.subList(listOffsets[ndx], listOffsets[ndx + 1]))
        }
    }

    private fun decodeVarlenNullableInt(dataBuffer: ByteBuffer,
                                offsetBuffer: ByteBuffer,
                                validityBitset: BitSet,
                                numberOfRecords: Int,
                                outputList: MutableList<List<Int>>) {
        val offsets = IntArray(numberOfRecords + 1)
        offsetBuffer.asIntBuffer().get(offsets)
        val data = IntArray(offsets[numberOfRecords])
        dataBuffer.asIntBuffer().get(data)
        for (offsetIndex in 0..<numberOfRecords) {
            val obsList = mutableListOf<Int>()
            outputList.add(obsList)
            for (ndx in offsets[offsetIndex] until offsets[offsetIndex + 1]) {
                obsList.add(
                    if (validityBitset.get(offsetIndex)) data[ndx] else missingInt
                )
            }

        }

    }

    private fun decodeNullableInt(dataBuffer: ByteBuffer,
                          validityBitset: BitSet,
                          numberOfRecords: Int,
                          outputList: MutableList<Int>) {
        val data = IntArray(numberOfRecords)
        dataBuffer.asIntBuffer().get(data)
        for (ndx in 0 until numberOfRecords) {
            outputList.add(
                if ( validityBitset.get(ndx) ) data[ndx] else missingInt
            )
        }

    }
}